import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import r2_score
from sklearn.cluster import KMeans
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array
from tensorflow.keras.utils import to_categorical
from PIL import Image
import numpy as np
import tensorflow as tf
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ReduceLROnPlateau
from tensorflow.keras.applications import VGG16
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization
from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping
from tensorflow.keras.models import Model
from tensorflow.keras import mixed_precision
from tensorflow.keras.applications import MobileNetV2


# à¸ªà¸£à¹‰à¸²à¸‡ sidebar
page = st.sidebar.radio("Select Page", ["Development - Machine Learning", "Model (Machine Learning)","Development - Neuron Network","Model (Neuron Network)"])

# à¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥
@st.cache_data
def load_data():
    df = pd.read_csv("Dataset/car_price.csv")
    df = df.sample(n=1500, random_state=42)  
    return df

df = load_data()

# à¹€à¸•à¸£à¸µà¸¢à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥
selected_features = ["Brand", "Year", "Engine_Size", "Fuel_Type", "Mileage", "Transmission", "Owner_Count", "Price"]
df = df[selected_features]
df.dropna(inplace=True)

# à¹à¸›à¸¥à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸«à¸¡à¸§à¸”à¸«à¸¡à¸¹à¹ˆà¹ƒà¸«à¹‰à¹€à¸›à¹‡à¸™à¸•à¸±à¸§à¹€à¸¥à¸‚
label_encoders = {}
categorical_columns = ["Brand", "Fuel_Type", "Transmission"]
for col in categorical_columns:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    label_encoders[col] = le

# à¹à¸¢à¸ Features à¹à¸¥à¸° Target
X = df.drop(columns=["Price"])
y = df["Price"]

# Standardization
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# à¹à¸šà¹ˆà¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ Train-Test
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

if page == "Development - Machine Learning":
    st.title('Development - Machine Learning')
    st.write('à¸§à¸´à¸˜à¸µà¸à¸²à¸£à¸à¸±à¸’à¸™à¸² Model - Machine Learning ')
    
    st.write("\n### à¸„à¸³à¸­à¸˜à¸´à¸šà¸²à¸¢à¹€à¸à¸µà¹ˆà¸¢à¸§à¸à¸±à¸š Dataset\n")
    st.write("\nDataset à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¸„à¸·à¸­ Car Price Dataset à¸—à¸µà¹ˆà¸¡à¸²à¸„à¸·à¸­ https://www.kaggle.com/  à¹‚à¸”à¸¢à¹ƒà¸Šà¹‰à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸—à¸³à¸™à¸²à¸¢à¸£à¸²à¸„à¸²à¸‚à¸­à¸‡à¸£à¸–à¸¢à¸™à¸•à¹Œ à¹‚à¸”à¸¢à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸›à¸£à¸°à¸à¸­à¸šà¹„à¸›à¸”à¹‰à¸§à¸¢ 10,000 à¸£à¸²à¸¢à¸à¸²à¸£ à¸‹à¸¶à¹ˆà¸‡à¹à¸•à¹ˆà¸¥à¸°à¹à¸–à¸§à¹à¸ªà¸”à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸‚à¸­à¸‡à¸£à¸–à¸¢à¸™à¸•à¹Œà¸«à¸™à¸¶à¹ˆà¸‡à¸„à¸±à¸™ à¸£à¸§à¸¡à¸–à¸¶à¸‡à¸„à¸¸à¸“à¸ªà¸¡à¸šà¸±à¸•à¸´à¸•à¹ˆà¸²à¸‡à¹† à¸—à¸µà¹ˆà¸¡à¸µà¸œà¸¥à¸•à¹ˆà¸­à¸£à¸²à¸„à¸² à¹€à¸Šà¹ˆà¸™ à¸¢à¸µà¹ˆà¸«à¹‰à¸­à¸£à¸–à¸¢à¸™à¸•à¹Œ à¸›à¸µà¸—à¸µà¹ˆà¸œà¸¥à¸´à¸• à¸‚à¸™à¸²à¸”à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸¢à¸™à¸•à¹Œ à¸›à¸£à¸°à¹€à¸ à¸—à¹€à¸Šà¸·à¹‰à¸­à¹€à¸à¸¥à¸´à¸‡ à¸›à¸£à¸°à¹€à¸ à¸—à¹€à¸à¸µà¸¢à¸£à¹Œ à¹à¸¥à¸°à¸£à¸°à¸¢à¸°à¸—à¸²à¸‡à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¸‡à¸²à¸™ à¹€à¸›à¹‡à¸™à¸•à¹‰à¸™\n")
    
    st.write("\n### à¸„à¸³à¸­à¸˜à¸´à¸šà¸²à¸¢à¸‚à¸­à¸‡à¹à¸•à¹ˆà¸¥à¸° Column\n")
    st.write("- **Brand:** à¸¢à¸µà¹ˆà¸«à¹‰à¸­à¸‚à¸­à¸‡à¸£à¸–à¸¢à¸™à¸•à¹Œ à¹€à¸Šà¹ˆà¸™ Toyota, BMW, Ford\n")
    st.write("- **Year:** à¸›à¸µà¸—à¸µà¹ˆà¸œà¸¥à¸´à¸• à¸¢à¸´à¹ˆà¸‡à¹ƒà¸«à¸¡à¹ˆà¸¢à¸´à¹ˆà¸‡à¸¡à¸µà¸£à¸²à¸„à¸²à¸ªà¸¹à¸‡\n")
    st.write("- **Engine_Size:** à¸‚à¸™à¸²à¸”à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸¢à¸™à¸•à¹Œ (à¸¥à¸´à¸•à¸£)\n")
    st.write("- **Fuel_Type:** à¸›à¸£à¸°à¹€à¸ à¸—à¹€à¸Šà¸·à¹‰à¸­à¹€à¸à¸¥à¸´à¸‡ (Petrol, Diesel, Hybrid, Electric)\n")
    st.write("- **Transmission:** à¸›à¸£à¸°à¹€à¸ à¸—à¹€à¸à¸µà¸¢à¸£à¹Œ (Manual, Automatic, Semi-Automatic)\n")
    st.write("- **Mileage:** à¸£à¸°à¸¢à¸°à¸—à¸²à¸‡à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¸‡à¸²à¸™ (à¸à¸´à¹‚à¸¥à¹€à¸¡à¸•à¸£) à¸¢à¸´à¹ˆà¸‡à¸¡à¸²à¸ à¸£à¸²à¸„à¸²à¸¡à¸±à¸à¸ˆà¸°à¸•à¹ˆà¸³à¸¥à¸‡\n")
    st.write("- **Owner_Count:** à¸ˆà¸³à¸™à¸§à¸™à¹€à¸ˆà¹‰à¸²à¸‚à¸­à¸‡à¹€à¸”à¸´à¸¡à¸‚à¸­à¸‡à¸£à¸– à¸¢à¸´à¹ˆà¸‡à¸™à¹‰à¸­à¸¢ à¸¢à¸´à¹ˆà¸‡à¸¡à¸µà¸¡à¸¹à¸¥à¸„à¹ˆà¸²à¸ªà¸¹à¸‡\n")
    st.write("- **Price:** à¸£à¸²à¸„à¸²à¸‚à¸­à¸‡à¸£à¸–à¸¢à¸™à¸•à¹Œ (à¹€à¸›à¹‰à¸²à¸«à¸¡à¸²à¸¢à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸—à¸³à¸™à¸²à¸¢)\n")
    
    st.write("\n### à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™à¸‚à¸­à¸‡à¹‚à¸„à¹‰à¸”\n")
    st.write("1. **à¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥:** à¹ƒà¸Šà¹‰à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™ `load_data()` à¹€à¸à¸·à¹ˆà¸­à¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸à¹„à¸Ÿà¸¥à¹Œ CSV à¹à¸¥à¸°à¸ªà¸¸à¹ˆà¸¡à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡ 1,500 à¸£à¸²à¸¢à¸à¸²à¸£à¹€à¸à¸·à¹ˆà¸­à¹ƒà¸Šà¹‰à¹ƒà¸™à¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ\n")
    st.write("2. **à¹€à¸•à¸£à¸µà¸¢à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥:** à¹€à¸¥à¸·à¸­à¸à¹€à¸‰à¸à¸²à¸°à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸—à¸µà¹ˆà¹€à¸à¸µà¹ˆà¸¢à¸§à¸‚à¹‰à¸­à¸‡ à¹à¸¥à¸°à¸ˆà¸±à¸”à¸à¸²à¸£à¸„à¹ˆà¸²à¸—à¸µà¹ˆà¸«à¸²à¸¢à¹„à¸› (`dropna()`)\n")
    st.write("3. **à¹à¸›à¸¥à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸«à¸¡à¸§à¸”à¸«à¸¡à¸¹à¹ˆà¹€à¸›à¹‡à¸™à¸•à¸±à¸§à¹€à¸¥à¸‚:** à¹ƒà¸Šà¹‰ `LabelEncoder()` à¹à¸›à¸¥à¸‡à¸„à¹ˆà¸²à¸‚à¸­à¸‡ `Brand`, `Fuel_Type`, à¹à¸¥à¸° `Transmission` à¹ƒà¸«à¹‰à¸­à¸¢à¸¹à¹ˆà¹ƒà¸™à¸£à¸¹à¸›à¸•à¸±à¸§à¹€à¸¥à¸‚\n")
    st.write("4. **à¹à¸¢à¸ Features à¹à¸¥à¸° Target:** à¹à¸¢à¸ `X` (à¸•à¸±à¸§à¹à¸›à¸£à¸•à¹‰à¸™) à¹à¸¥à¸° `y` (à¸£à¸²à¸„à¸²à¸‚à¸­à¸‡à¸£à¸–à¸¢à¸™à¸•à¹Œ)\n")
    st.write("5. **Standardization:** à¹ƒà¸Šà¹‰ `StandardScaler()` à¹€à¸à¸·à¹ˆà¸­à¸›à¸£à¸±à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸«à¹‰à¸­à¸¢à¸¹à¹ˆà¹ƒà¸™à¸Šà¹ˆà¸§à¸‡à¸¡à¸²à¸•à¸£à¸à¸²à¸™\n")
    st.write("6. **à¹à¸šà¹ˆà¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ Train-Test:** à¹ƒà¸Šà¹‰ `train_test_split()` à¹à¸šà¹ˆà¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸›à¹‡à¸™ 80% à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸¶à¸à¹‚à¸¡à¹€à¸”à¸¥ à¹à¸¥à¸° 20% à¸ªà¸³à¸«à¸£à¸±à¸šà¸—à¸”à¸ªà¸­à¸š\n")
    st.write("7. **à¹€à¸¥à¸·à¸­à¸à¹à¸¥à¸°à¸à¸¶à¸à¹‚à¸¡à¹€à¸”à¸¥:**\n   - **Random Forest:** à¹ƒà¸Šà¹‰ `RandomForestRegressor` à¸—à¸³à¸™à¸²à¸¢à¸£à¸²à¸„à¸² à¹à¸¥à¸°à¹à¸ªà¸”à¸‡à¸œà¸¥ RÂ² Score\n   - **K-Means:** à¹ƒà¸Šà¹‰ `KMeans` à¸ˆà¸±à¸”à¸à¸¥à¸¸à¹ˆà¸¡à¸£à¸–à¸¢à¸™à¸•à¹Œà¹€à¸›à¹‡à¸™ 5 à¸à¸¥à¸¸à¹ˆà¸¡ à¹à¸¥à¸°à¹à¸ªà¸”à¸‡à¸à¸²à¸£à¸à¸£à¸°à¸ˆà¸²à¸¢à¸•à¸±à¸§à¸‚à¸­à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥\n")
    st.write("8. **à¸—à¸³à¸™à¸²à¸¢à¸„à¹ˆà¸²à¸ˆà¸²à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸«à¸¡à¹ˆ:** à¸£à¸±à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰ à¹à¸›à¸¥à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸«à¹‰à¸•à¸£à¸‡à¸à¸±à¸šà¸£à¸¹à¸›à¹à¸šà¸šà¸‚à¸­à¸‡à¹‚à¸¡à¹€à¸”à¸¥ à¹à¸¥à¹‰à¸§à¸—à¸³à¸à¸²à¸£à¸à¸¢à¸²à¸à¸£à¸“à¹Œà¸£à¸²à¸„à¸² à¸«à¸£à¸·à¸­à¸à¸¥à¸¸à¹ˆà¸¡à¸‚à¸­à¸‡à¸£à¸–à¸¢à¸™à¸•à¹Œ\n")
    st.write("\n### à¸—à¸¤à¸©à¸à¸µà¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™à¸‚à¸­à¸‡à¹‚à¸¡à¹€à¸”à¸¥\n")
    st.write("- **Random Forest Regression:** à¹€à¸›à¹‡à¸™à¹€à¸—à¸„à¸™à¸´à¸„à¸‚à¸­à¸‡à¸à¸²à¸£à¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰à¹à¸šà¸š Supervised Learning à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰ Decision Trees à¸«à¸¥à¸²à¸¢à¸•à¹‰à¸™à¹ƒà¸™à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™à¸£à¹ˆà¸§à¸¡à¸à¸±à¸™à¹€à¸à¸·à¹ˆà¸­à¸ªà¸£à¹‰à¸²à¸‡à¹à¸šà¸šà¸ˆà¸³à¸¥à¸­à¸‡à¸—à¸µà¹ˆà¸¡à¸µà¸„à¸§à¸²à¸¡à¹à¸¡à¹ˆà¸™à¸¢à¸³à¸ªà¸¹à¸‡ à¹‚à¸”à¸¢à¹ƒà¸Šà¹‰à¸§à¸´à¸˜à¸µà¸à¸²à¸£ Bagging à¹ƒà¸™à¸à¸²à¸£à¸£à¸§à¸¡à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¸‚à¸­à¸‡à¸•à¹‰à¸™à¹„à¸¡à¹‰à¹à¸•à¹ˆà¸¥à¸°à¸•à¹‰à¸™\n")
    st.write("- **K-Means Clustering:** à¹€à¸›à¹‡à¸™à¹€à¸—à¸„à¸™à¸´à¸„à¸‚à¸­à¸‡ Unsupervised Learning à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¹ƒà¸™à¸à¸²à¸£à¸ˆà¸±à¸”à¸à¸¥à¸¸à¹ˆà¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹‚à¸”à¸¢à¸à¸²à¸£à¹à¸šà¹ˆà¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸­à¸­à¸à¹€à¸›à¹‡à¸™ K à¸à¸¥à¸¸à¹ˆà¸¡à¸•à¸²à¸¡à¸¥à¸±à¸à¸©à¸“à¸°à¸‚à¸­à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸„à¸¥à¹‰à¸²à¸¢à¸à¸±à¸™ à¸‹à¸¶à¹ˆà¸‡à¹€à¸«à¸¡à¸²à¸°à¸à¸±à¸šà¸à¸²à¸£à¸„à¹‰à¸™à¸«à¸²à¸£à¸¹à¸›à¹à¸šà¸šà¸‚à¸­à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¸—à¸£à¸²à¸šà¸¥à¹ˆà¸§à¸‡à¸«à¸™à¹‰à¸²\n")




elif page == "Model (Machine Learning)":
    st.title('Model (Machine Learning)')
    model_type = st.selectbox("à¹€à¸¥à¸·à¸­à¸à¹‚à¸¡à¹€à¸”à¸¥à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£", ["Random Forest", "K-Means"])

    if model_type == "Random Forest":
        # à¸ªà¸£à¹‰à¸²à¸‡à¹à¸¥à¸°à¸à¸¶à¸ Random Forest
        model = RandomForestRegressor(n_estimators=100, random_state=42)
        model.fit(X_train, y_train)

        y_pred = model.predict(X_test)

        # à¸„à¸³à¸™à¸§à¸“à¸„à¹ˆà¸² RÂ²
        r2 = r2_score(y_test, y_pred)

        st.write("### Model Performance: (Random Forest - Regression)")
        st.write(f"**RÂ²**: {r2:.4f}")  # à¹à¸ªà¸”à¸‡à¸„à¹ˆà¸² RÂ²

        # à¹à¸ªà¸”à¸‡à¸à¸£à¸²à¸Ÿ Regression
        fig, ax = plt.subplots()
        ax.scatter(y_test, y_pred, alpha=0.5, label="Predictions")
        ax.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--', label="Ideal Prediction")
        ax.set_xlabel("Actual Price")
        ax.set_ylabel("Predicted Price")
        ax.legend()
        st.pyplot(fig)

        # à¸£à¸±à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸«à¸¡à¹ˆà¸ˆà¸²à¸à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰
        st.write("### à¸—à¸³à¸™à¸²à¸¢à¸£à¸²à¸„à¸²à¸‚à¸­à¸‡à¸£à¸–à¹ƒà¸«à¸¡à¹ˆ")
        brand = st.selectbox("à¹€à¸¥à¸·à¸­à¸à¸¢à¸µà¹ˆà¸«à¹‰à¸­", label_encoders["Brand"].classes_)
        year = st.number_input("à¹€à¸¥à¸·à¸­à¸à¸›à¸µà¸—à¸µà¹ˆà¸œà¸¥à¸´à¸•", min_value=2000, max_value=2023, value=2015)
        engine_size = st.number_input("à¸‚à¸™à¸²à¸”à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸¢à¸™à¸•à¹Œ (à¸¥à¸´à¸•à¸£)", min_value=0.8, max_value=5.0, value=1.8)
        fuel_type = st.selectbox("à¹€à¸¥à¸·à¸­à¸à¸›à¸£à¸°à¹€à¸ à¸—à¹€à¸Šà¸·à¹‰à¸­à¹€à¸à¸¥à¸´à¸‡", label_encoders["Fuel_Type"].classes_)
        mileage = st.number_input("à¸£à¸°à¸¢à¸°à¸—à¸²à¸‡à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¸‡à¸²à¸™ (à¸à¸´à¹‚à¸¥à¹€à¸¡à¸•à¸£)", min_value=0, value=9000)
        transmission = st.selectbox("à¹€à¸¥à¸·à¸­à¸à¸›à¸£à¸°à¹€à¸ à¸—à¹€à¸à¸µà¸¢à¸£à¹Œ", label_encoders["Transmission"].classes_)
        owner_count = st.number_input("à¸ˆà¸³à¸™à¸§à¸™à¹€à¸ˆà¹‰à¸²à¸‚à¸­à¸‡", min_value=1, max_value=5, value=2)

        # à¹à¸›à¸¥à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸£à¸±à¸šà¹€à¸‚à¹‰à¸²à¸¡à¸²
        brand_encoded = label_encoders["Brand"].transform([brand])[0]
        fuel_type_encoded = label_encoders["Fuel_Type"].transform([fuel_type])[0]
        transmission_encoded = label_encoders["Transmission"].transform([transmission])[0]

        new_data = np.array([[brand_encoded, year, engine_size, fuel_type_encoded, mileage, transmission_encoded, owner_count]])
        new_data_scaled = scaler.transform(new_data)

        # à¸—à¸³à¸™à¸²à¸¢à¸£à¸²à¸„à¸²à¸”à¹‰à¸§à¸¢à¹‚à¸¡à¹€à¸”à¸¥ Random Forest
        predicted_price = model.predict(new_data_scaled)
        st.write(f"**à¸£à¸²à¸„à¸²à¸—à¸µà¹ˆà¸—à¸³à¸™à¸²à¸¢à¹„à¸”à¹‰**: {predicted_price[0]:,.2f} dollar")

        # à¹à¸ªà¸”à¸‡à¸ˆà¸¸à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸«à¸¡à¹ˆà¹ƒà¸™à¸à¸£à¸²à¸Ÿ (à¸ˆà¸¸à¸”à¹ƒà¸«à¸¡à¹ˆà¸ˆà¸°à¸¡à¸µà¸ªà¸µà¹à¸”à¸‡)
        fig, ax = plt.subplots()
        ax.scatter(y_test, y_pred, alpha=0.5, label="Predictions")
        ax.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--', label="Ideal Prediction")

        # à¹à¸ªà¸”à¸‡à¸ˆà¸¸à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸«à¸¡à¹ˆà¸—à¸µà¹ˆà¸—à¸³à¸™à¸²à¸¢à¹„à¸§à¹‰
        ax.scatter(predicted_price[0], predicted_price[0], color='red', marker='o', s=100, label="New Data (Predicted)")
        
        ax.set_xlabel("Actual Price")
        ax.set_ylabel("Predicted Price")
        ax.legend()
        st.pyplot(fig)

    elif model_type == "K-Means":
        # à¸—à¸³à¸à¸²à¸£à¸à¸¶à¸ K-Means
        kmeans = KMeans(n_clusters=5, n_init=10, random_state=42)
        df["Cluster"] = kmeans.fit_predict(X_scaled)

        st.write("### Clustering Results: (K-Means)")

        # à¹à¸ªà¸”à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹à¸•à¹ˆà¸¥à¸°à¸à¸¥à¸¸à¹ˆà¸¡
        for i in range(5):
            st.write(f"#### Cluster {i}")
            cluster_data = df[df["Cluster"] == i]
            st.write(f"Number of data points: {len(cluster_data)}")
            st.write(cluster_data.describe())  # à¹à¸ªà¸”à¸‡à¸ªà¸–à¸´à¸•à¸´à¹€à¸šà¸·à¹‰à¸­à¸‡à¸•à¹‰à¸™à¸‚à¸­à¸‡à¹à¸•à¹ˆà¸¥à¸°à¸à¸¥à¸¸à¹ˆà¸¡

        # à¸à¸£à¸²à¸Ÿà¹à¸ªà¸”à¸‡à¸à¸²à¸£à¸à¸£à¸°à¸ˆà¸²à¸¢à¸‚à¸­à¸‡ Cluster
        fig, ax = plt.subplots()
        scatter = ax.scatter(df["Engine_Size"], df["Price"], c=df["Cluster"], cmap="viridis", alpha=0.5)
        ax.set_xlabel("Engine Size")
        ax.set_ylabel("Mileage")
        legend1 = ax.legend(*scatter.legend_elements(), title="Clusters")
        ax.add_artist(legend1)
        st.pyplot(fig)

        # à¸£à¸±à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸«à¸¡à¹ˆà¸ˆà¸²à¸à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰
        st.write("### à¸—à¸³à¸™à¸²à¸¢à¸à¸¥à¸¸à¹ˆà¸¡à¸‚à¸­à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸«à¸¡à¹ˆ")
        brand = st.selectbox("à¹€à¸¥à¸·à¸­à¸à¸¢à¸µà¹ˆà¸«à¹‰à¸­", label_encoders["Brand"].classes_)
        year = st.number_input("à¹€à¸¥à¸·à¸­à¸à¸›à¸µà¸—à¸µà¹ˆà¸œà¸¥à¸´à¸•", min_value=2000, max_value=2023, value=2015)
        engine_size = st.number_input("à¸‚à¸™à¸²à¸”à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸¢à¸™à¸•à¹Œ (à¸¥à¸´à¸•à¸£)", min_value=0.8, max_value=5.0, value=1.8)
        fuel_type = st.selectbox("à¹€à¸¥à¸·à¸­à¸à¸›à¸£à¸°à¹€à¸ à¸—à¹€à¸Šà¸·à¹‰à¸­à¹€à¸à¸¥à¸´à¸‡", label_encoders["Fuel_Type"].classes_)
        mileage = st.number_input("à¸£à¸°à¸¢à¸°à¸—à¸²à¸‡à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¸‡à¸²à¸™ (à¸à¸´à¹‚à¸¥à¹€à¸¡à¸•à¸£)", min_value=0, value=9000)
        transmission = st.selectbox("à¹€à¸¥à¸·à¸­à¸à¸›à¸£à¸°à¹€à¸ à¸—à¹€à¸à¸µà¸¢à¸£à¹Œ", label_encoders["Transmission"].classes_)
        owner_count = st.number_input("à¸ˆà¸³à¸™à¸§à¸™à¹€à¸ˆà¹‰à¸²à¸‚à¸­à¸‡", min_value=1, max_value=5, value=2)

        # à¹à¸›à¸¥à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸£à¸±à¸šà¹€à¸‚à¹‰à¸²à¸¡à¸²
        brand_encoded = label_encoders["Brand"].transform([brand])[0]
        fuel_type_encoded = label_encoders["Fuel_Type"].transform([fuel_type])[0]
        transmission_encoded = label_encoders["Transmission"].transform([transmission])[0]

        new_data = np.array([[brand_encoded, year, engine_size, fuel_type_encoded, mileage, transmission_encoded, owner_count]])
        new_data_scaled = scaler.transform(new_data)

        # à¸—à¸³à¸™à¸²à¸¢à¸à¸¥à¸¸à¹ˆà¸¡à¸‚à¸­à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸«à¸¡à¹ˆ
        predicted_cluster = kmeans.predict(new_data_scaled)
        st.write(f"### Predicted Cluster: {predicted_cluster[0]}")

        # à¹à¸ªà¸”à¸‡à¸ˆà¸¸à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸«à¸¡à¹ˆà¹ƒà¸™à¸à¸£à¸²à¸Ÿà¹€à¸”à¸´à¸¡
        fig, ax = plt.subplots()
        scatter = ax.scatter(df["Engine_Size"], df["Price"], c=df["Cluster"], cmap="viridis", alpha=0.5)
        ax.set_xlabel("Engine Size")
        ax.set_ylabel("Mileage")
        
        # à¹à¸ªà¸”à¸‡à¸ˆà¸¸à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸«à¸¡à¹ˆà¸—à¸µà¹ˆà¸—à¸³à¸™à¸²à¸¢à¹„à¸§à¹‰à¹ƒà¸™à¸à¸£à¸²à¸Ÿà¹€à¸”à¸´à¸¡ (à¸ˆà¸¸à¸”à¹ƒà¸«à¸¡à¹ˆà¸ˆà¸°à¸¡à¸µà¸ªà¸µà¹à¸”à¸‡)
        ax.scatter(engine_size, mileage, color='red', marker='o', s=100, label="New Data (Predicted)")

        # à¹€à¸à¸´à¹ˆà¸¡à¹à¸ªà¸”à¸‡ Legend
        legend1 = ax.legend(*scatter.legend_elements(), title="Clusters")
        ax.add_artist(legend1)
        ax.legend()
        st.pyplot(fig)

elif page == "Development - Neuron Network":
    st.title('Development - Neuron Network')
    st.write('à¸§à¸´à¸˜à¸µà¸à¸²à¸£à¸à¸±à¸’à¸™à¸² Model - CNN ')
    
    st.write("\n### à¸„à¸³à¸­à¸˜à¸´à¸šà¸²à¸¢à¹€à¸à¸µà¹ˆà¸¢à¸§à¸à¸±à¸š Dataset\n")
    st.write("\nDataset à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¸„à¸·à¸­ Dog vs Cat Dataset à¹à¸«à¸¥à¹ˆà¸‡à¸—à¸µà¹ˆà¸¡à¸²à¸„à¸·à¸­ https://www.kaggle.com/ à¹‚à¸”à¸¢à¹ƒà¸Šà¹‰à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸ˆà¸³à¹à¸™à¸à¸ à¸²à¸à¸ªà¸¸à¸™à¸±à¸‚à¹à¸¥à¸°à¹à¸¡à¸§ à¹‚à¸”à¸¢à¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸£à¸¹à¸›à¸ à¸²à¸à¸—à¸µà¹ˆà¸–à¸¹à¸à¹à¸šà¹ˆà¸‡à¹€à¸›à¹‡à¸™à¸«à¸¡à¸§à¸”à¸«à¸¡à¸¹à¹ˆà¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸¶à¸ (train) à¹à¸¥à¸°à¸—à¸”à¸ªà¸­à¸š (test)\n")
    
    st.write("\n### à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™à¸‚à¸­à¸‡à¹‚à¸„à¹‰à¸”\n")
    st.write("1. **à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸² TensorFlow Policy:** à¸à¸³à¸«à¸™à¸”à¹ƒà¸«à¹‰à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ precision à¹à¸šà¸š `mixed_float16` à¹€à¸à¸·à¹ˆà¸­à¹€à¸à¸´à¹ˆà¸¡à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸à¸à¸²à¸£à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¸šà¸™ GPU\n")
    st.write("2. **Data Augmentation:** à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¸ à¸²à¸à¹€à¸à¸·à¹ˆà¸­à¹€à¸à¸´à¹ˆà¸¡à¸„à¸§à¸²à¸¡à¸«à¸¥à¸²à¸à¸«à¸¥à¸²à¸¢à¸‚à¸­à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ à¹‚à¸”à¸¢à¹ƒà¸Šà¹‰ `ImageDataGenerator()`\n")
    st.write("3. **à¹‚à¸«à¸¥à¸”à¹à¸¥à¸°à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¹‚à¸¡à¹€à¸”à¸¥ MobileNetV2:** à¹ƒà¸Šà¹‰à¹‚à¸¡à¹€à¸”à¸¥à¸à¸·à¹‰à¸™à¸à¸²à¸™à¸—à¸µà¹ˆà¸–à¸¹à¸à¸à¸¶à¸à¸¡à¸²à¹à¸¥à¹‰à¸§ à¹à¸¥à¸°à¹€à¸à¸´à¹ˆà¸¡à¸Šà¸±à¹‰à¸™ Fully Connected Layer\n")
    st.write("4. **Train Model:** à¹ƒà¸Šà¹‰ Optimizer `Adam` à¹à¸¥à¸° Loss Function `binary_crossentropy` à¹€à¸—à¸£à¸™à¹‚à¸¡à¹€à¸”à¸¥à¹€à¸à¸·à¹ˆà¸­à¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰à¸à¸²à¸£à¸ˆà¸³à¹à¸™à¸à¸ à¸²à¸\n")
    st.write("5. **Prediction:** à¸£à¸±à¸šà¸ à¸²à¸à¸ˆà¸²à¸à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰à¹à¸¥à¸°à¸—à¸³à¸™à¸²à¸¢à¸§à¹ˆà¸²à¹€à¸›à¹‡à¸™à¸ªà¸¸à¸™à¸±à¸‚à¸«à¸£à¸·à¸­à¹à¸¡à¸§\n")
    
    st.write("\n### à¸—à¸¤à¸©à¸à¸µà¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™à¸‚à¸­à¸‡à¹‚à¸¡à¹€à¸”à¸¥\n")
    st.write("- **Convolutional Neural Network (CNN):** à¹€à¸›à¹‡à¸™à¹‚à¸„à¸£à¸‡à¸‚à¹ˆà¸²à¸¢à¸›à¸£à¸°à¸ªà¸²à¸—à¹€à¸—à¸µà¸¢à¸¡à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¸à¸±à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ à¸²à¸ à¹‚à¸”à¸¢à¸¡à¸µà¸Šà¸±à¹‰à¸™ Convolution, Pooling à¹à¸¥à¸° Fully Connected à¹€à¸à¸·à¹ˆà¸­à¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰à¸„à¸¸à¸“à¸¥à¸±à¸à¸©à¸“à¸°à¸‚à¸­à¸‡à¸ à¸²à¸\n")
    st.write("- **MobileNetV2:** à¹€à¸›à¹‡à¸™à¹‚à¸¡à¹€à¸”à¸¥à¸—à¸µà¹ˆà¸–à¸¹à¸à¸­à¸­à¸à¹à¸šà¸šà¸¡à¸²à¹ƒà¸«à¹‰à¹€à¸šà¸²à¹à¸¥à¸°à¹€à¸£à¹‡à¸§à¸‚à¸¶à¹‰à¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¸‡à¸²à¸™ Image Classification à¹‚à¸”à¸¢à¹ƒà¸Šà¹‰ Depthwise Separable Convolutions à¹€à¸à¸·à¹ˆà¸­à¸¥à¸”à¸ˆà¸³à¸™à¸§à¸™à¸à¸²à¸£à¸²à¸¡à¸´à¹€à¸•à¸­à¸£à¹Œ\n")


elif page == "Model (Neuron Network)":
    policy = tf.keras.mixed_precision.Policy('mixed_float16')
    tf.keras.mixed_precision.set_global_policy(policy)
    print("GPUs:", tf.config.list_physical_devices('GPU'))

    # à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸² Dataset à¹à¸¥à¸° Parameters
    dataset_path = "Dataset/"
    img_size = (64, 64)
    batch_size = 32
    epochs = 15

    # Data Augmentation
    train_datagen = ImageDataGenerator(
        rescale=1./255,
        rotation_range=20,
        width_shift_range=0.2,
        height_shift_range=0.2,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True,
        fill_mode='nearest',
        validation_split=0.2
    )

    train_generator = train_datagen.flow_from_directory(
        dataset_path + 'train',
        target_size=img_size,
        batch_size=batch_size,
        class_mode='binary',
        subset='training'
    )

    val_generator = train_datagen.flow_from_directory(
        dataset_path + 'train',
        target_size=img_size,
        batch_size=batch_size,
        class_mode='binary',
        subset='validation'
    )

    test_datagen = ImageDataGenerator(rescale=1./255)
    test_generator = test_datagen.flow_from_directory(
        dataset_path + 'test',
        target_size=img_size,
        batch_size=batch_size,
        class_mode='binary'
    )

    # à¹‚à¸«à¸¥à¸”à¹‚à¸¡à¹€à¸”à¸¥à¸à¸·à¹‰à¸™à¸à¸²à¸™ MobileNetV2
    from tensorflow.keras.applications import MobileNetV2
    from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D
    from tensorflow.keras import Model
    from tensorflow.keras.optimizers import Adam
    from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping

    # à¹‚à¸«à¸¥à¸”à¹‚à¸¡à¹€à¸”à¸¥à¸à¸·à¹‰à¸™à¸à¸²à¸™ MobileNetV2
    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(64, 64, 3))

    # Freeze Layers
    for layer in base_model.layers:
        layer.trainable = False

    # à¹€à¸à¸´à¹ˆà¸¡à¸Šà¸±à¹‰à¸™ Dense à¹à¸¥à¸° BatchNormalization
    x = base_model.output
    x = GlobalAveragePooling2D()(x)
    x = BatchNormalization()(x)
    x = Dense(256, activation='relu')(x)
    x = BatchNormalization()(x)
    x = Dropout(0.3)(x)
    x = Dense(128, activation='relu')(x)
    x = BatchNormalization()(x)
    x = Dropout(0.3)(x)
    x = Dense(64, activation='relu')(x)
    x = BatchNormalization()(x)
    x = Dense(32, activation='relu')(x)  
    x = Dense(16, activation='relu')(x)   
    predictions = Dense(1, activation='sigmoid')(x)

    # à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸¡à¹€à¸”à¸¥à¹ƒà¸«à¸¡à¹ˆ
    model = Model(inputs=base_model.input, outputs=predictions)
    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])

    # Callbacks
    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)
    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

    # à¹€à¸—à¸£à¸™à¹‚à¸¡à¹€à¸”à¸¥
    st.write('### Training CNN Model')
    history = model.fit(
        train_generator, 
        validation_data=val_generator, 
        epochs=epochs,
        callbacks=[reduce_lr, early_stopping]
    )

    # à¹à¸ªà¸”à¸‡à¸à¸£à¸²à¸Ÿ Accuracy
    import matplotlib.pyplot as plt
    fig, ax = plt.subplots()
    ax.plot(history.history['accuracy'], label='Train Accuracy')
    ax.plot(history.history['val_accuracy'], label='Validation Accuracy')
    ax.set_xlabel("Epochs")
    ax.set_ylabel("Accuracy")
    ax.legend()
    st.pyplot(fig)

    st.write("### Model Training Completed!")

    # à¸£à¸±à¸šà¸£à¸¹à¸›à¸ à¸²à¸à¸ˆà¸²à¸à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰
    st.write("### Upload an image for prediction:")
    uploaded_file = st.file_uploader("Choose an image...", type=["jpg", "png", "jpeg"])

    if uploaded_file is not None:
        # à¹à¸ªà¸”à¸‡à¸ à¸²à¸à¸—à¸µà¹ˆà¸­à¸±à¸›à¹‚à¸«à¸¥à¸”
        image = Image.open(uploaded_file)
        st.image(image, caption='Uploaded Image', use_column_width=True)

        # à¸›à¸£à¸±à¸šà¸‚à¸™à¸²à¸”à¸ à¸²à¸à¹ƒà¸«à¹‰à¸•à¸£à¸‡à¸à¸±à¸šà¸‚à¸™à¸²à¸”à¸—à¸µà¹ˆà¹‚à¸¡à¹€à¸”à¸¥à¸•à¹‰à¸­à¸‡à¸à¸²à¸£ (64x64)
        image = image.resize((64, 64))
        image_array = img_to_array(image)  # à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹€à¸›à¹‡à¸™à¸­à¸²à¹€à¸£à¸¢à¹Œ
        image_array = np.expand_dims(image_array, axis=0)  # à¹€à¸à¸´à¹ˆà¸¡à¸¡à¸´à¸•à¸´à¹ƒà¸«à¹‰à¸•à¸£à¸‡à¸à¸±à¸š input à¸‚à¸­à¸‡à¹‚à¸¡à¹€à¸”à¸¥
        image_array = image_array / 255.0  # Normalize à¸„à¹ˆà¸²à¹ƒà¸«à¹‰à¹ƒà¸™à¸Šà¹ˆà¸§à¸‡ [0,1]

        # à¸—à¸³à¸™à¸²à¸¢à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ
        prediction = model.predict(image_array)

        # à¹à¸ªà¸”à¸‡à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¸à¸²à¸£à¸—à¸³à¸™à¸²à¸¢
        if prediction[0] > 0.5:
            st.write("This is a Dog! ğŸ¶")
        else:
            st.write("This is a Cat! ğŸ±")


